{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c6720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca150639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam\n",
    "\n",
    "# local\n",
    "from models import SparseAutoencoder\n",
    "from dataset import EmbeddingDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34abede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../data/external/adata_sample.h5ad\")\n",
    "embeddings_data = adata.obsm[\"geneformer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099cb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = EmbeddingDataset(embeddings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e45c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SparseAutoencoder(512, 1024, expanded_ratio=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6098f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = random_split(dset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad1de16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158423ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches 0, steps 1, loss (recon_loss): 0.2937175929546356, loss (sparsity): 0.10660004615783691, loss (total): 0.2938241958618164\n",
      "epoches 0, steps 2, loss (recon_loss): 0.08938649296760559, loss (sparsity): 0.07742805778980255, loss (total): 0.08946391940116882\n",
      "epoches 0, steps 3, loss (recon_loss): 0.10133455693721771, loss (sparsity): 0.07861055433750153, loss (total): 0.10141316801309586\n",
      "epoches 0, steps 4, loss (recon_loss): 0.09201420098543167, loss (sparsity): 0.08482982963323593, loss (total): 0.09209903329610825\n",
      "epoches 0, steps 5, loss (recon_loss): 0.10279570519924164, loss (sparsity): 0.07272199541330338, loss (total): 0.10286843031644821\n",
      "epoches 0, steps 6, loss (recon_loss): 0.07029101997613907, loss (sparsity): 0.0804959088563919, loss (total): 0.07037151604890823\n",
      "epoches 0, steps 7, loss (recon_loss): 0.07630794495344162, loss (sparsity): 0.08493424952030182, loss (total): 0.07639288157224655\n",
      "epoches 0, steps 8, loss (recon_loss): 0.046384297311306, loss (sparsity): 0.08144455403089523, loss (total): 0.04646574333310127\n",
      "epoches 0, steps 9, loss (recon_loss): 0.0619833767414093, loss (sparsity): 0.07087182253599167, loss (total): 0.06205425038933754\n",
      "epoches 0, steps 10, loss (recon_loss): 0.04715801030397415, loss (sparsity): 0.07499206066131592, loss (total): 0.04723300412297249\n",
      "epoches 0, steps 11, loss (recon_loss): 0.05559150129556656, loss (sparsity): 0.08733192086219788, loss (total): 0.0556788332760334\n",
      "epoches 0, steps 12, loss (recon_loss): 0.049219533801078796, loss (sparsity): 0.08914557099342346, loss (total): 0.04930867999792099\n",
      "epoches 0, steps 13, loss (recon_loss): 0.033849503844976425, loss (sparsity): 0.08165962994098663, loss (total): 0.03393116220831871\n",
      "epoches 0, steps 14, loss (recon_loss): 0.048746898770332336, loss (sparsity): 0.0842430591583252, loss (total): 0.048831142485141754\n",
      "epoches 0, steps 15, loss (recon_loss): 0.04456411302089691, loss (sparsity): 0.08043479919433594, loss (total): 0.0446445494890213\n",
      "epoches 0, steps 16, loss (recon_loss): 0.033830128610134125, loss (sparsity): 0.07838338613510132, loss (total): 0.03390851244330406\n",
      "epoches 0, steps 17, loss (recon_loss): 0.03808986023068428, loss (sparsity): 0.0845143049955368, loss (total): 0.038174375891685486\n",
      "epoches 0, steps 18, loss (recon_loss): 0.03770746290683746, loss (sparsity): 0.08368870615959167, loss (total): 0.03779115155339241\n",
      "epoches 0, steps 19, loss (recon_loss): 0.028692301362752914, loss (sparsity): 0.07895946502685547, loss (total): 0.028771260753273964\n",
      "epoches 0, steps 20, loss (recon_loss): 0.03069152683019638, loss (sparsity): 0.07705963402986526, loss (total): 0.030768586322665215\n",
      "epoches 0, steps 21, loss (recon_loss): 0.03089560754597187, loss (sparsity): 0.08019500970840454, loss (total): 0.03097580187022686\n",
      "epoches 0, steps 22, loss (recon_loss): 0.029022013768553734, loss (sparsity): 0.08058145642280579, loss (total): 0.029102595522999763\n",
      "epoches 0, steps 23, loss (recon_loss): 0.02730485051870346, loss (sparsity): 0.08319547772407532, loss (total): 0.02738804556429386\n",
      "epoches 0, steps 24, loss (recon_loss): 0.02819574624300003, loss (sparsity): 0.08543559908866882, loss (total): 0.028281182050704956\n",
      "epoches 0, steps 25, loss (recon_loss): 0.021991614252328873, loss (sparsity): 0.08063794672489166, loss (total): 0.02207225188612938\n",
      "epoches 0, steps 26, loss (recon_loss): 0.025302965193986893, loss (sparsity): 0.07841628789901733, loss (total): 0.025381380692124367\n",
      "epoches 0, steps 27, loss (recon_loss): 0.024913128465414047, loss (sparsity): 0.0795188844203949, loss (total): 0.024992646649479866\n",
      "epoches 0, steps 28, loss (recon_loss): 0.024812087416648865, loss (sparsity): 0.08039224147796631, loss (total): 0.024892479181289673\n",
      "epoches 0, steps 29, loss (recon_loss): 0.022150013595819473, loss (sparsity): 0.08137773722410202, loss (total): 0.022231390699744225\n",
      "epoches 0, steps 30, loss (recon_loss): 0.023604141548275948, loss (sparsity): 0.08121774345636368, loss (total): 0.023685358464717865\n",
      "epoches 0, steps 31, loss (recon_loss): 0.021547753363847733, loss (sparsity): 0.0781460553407669, loss (total): 0.021625898778438568\n",
      "epoches 0, steps 32, loss (recon_loss): 0.027447624132037163, loss (sparsity): 0.08133542537689209, loss (total): 0.02752896025776863\n",
      "epoches 0, steps 33, loss (recon_loss): 0.021809300407767296, loss (sparsity): 0.08022185415029526, loss (total): 0.021889522671699524\n",
      "epoches 0, steps 34, loss (recon_loss): 0.019686991348862648, loss (sparsity): 0.08207482099533081, loss (total): 0.01976906694471836\n",
      "epoches 0, steps 35, loss (recon_loss): 0.018546346575021744, loss (sparsity): 0.08229821175336838, loss (total): 0.018628645688295364\n",
      "epoches 0, steps 36, loss (recon_loss): 0.02206849679350853, loss (sparsity): 0.0838339626789093, loss (total): 0.022152330726385117\n",
      "epoches 0, steps 37, loss (recon_loss): 0.019189981743693352, loss (sparsity): 0.08114852011203766, loss (total): 0.019271129742264748\n",
      "epoches 0, steps 38, loss (recon_loss): 0.021627577021718025, loss (sparsity): 0.07770241051912308, loss (total): 0.021705279126763344\n",
      "epoches 0, steps 39, loss (recon_loss): 0.020043466240167618, loss (sparsity): 0.07877722382545471, loss (total): 0.020122243091464043\n",
      "epoches 0, steps 40, loss (recon_loss): 0.021430769935250282, loss (sparsity): 0.08006738126277924, loss (total): 0.021510837599635124\n",
      "epoches 0, steps 41, loss (recon_loss): 0.019098296761512756, loss (sparsity): 0.08205749094486237, loss (total): 0.019180353730916977\n",
      "epoches 0, steps 42, loss (recon_loss): 0.017341842874884605, loss (sparsity): 0.0827641710639, loss (total): 0.017424607649445534\n",
      "epoches 0, steps 43, loss (recon_loss): 0.013873313553631306, loss (sparsity): 0.0811508297920227, loss (total): 0.013954464346170425\n",
      "epoches 0, steps 44, loss (recon_loss): 0.01548642385751009, loss (sparsity): 0.08229682594537735, loss (total): 0.015568721108138561\n",
      "epoches 0, steps 45, loss (recon_loss): 0.016786839812994003, loss (sparsity): 0.08236008882522583, loss (total): 0.01686920039355755\n",
      "epoches 0, steps 46, loss (recon_loss): 0.015700392425060272, loss (sparsity): 0.08168306201696396, loss (total): 0.015782075002789497\n",
      "epoches 0, steps 47, loss (recon_loss): 0.016136927530169487, loss (sparsity): 0.0825648382306099, loss (total): 0.016219493001699448\n",
      "epoches 0, steps 48, loss (recon_loss): 0.017126230522990227, loss (sparsity): 0.08393555879592896, loss (total): 0.01721016690135002\n",
      "epoches 0, steps 49, loss (recon_loss): 0.016102537512779236, loss (sparsity): 0.08304658532142639, loss (total): 0.016185583546757698\n",
      "epoches 0, steps 50, loss (recon_loss): 0.015382051467895508, loss (sparsity): 0.08264129608869553, loss (total): 0.015464692376554012\n",
      "epoches 0, steps 51, loss (recon_loss): 0.015899132937192917, loss (sparsity): 0.08187620341777802, loss (total): 0.015981009230017662\n",
      "epoches 0, steps 52, loss (recon_loss): 0.014853142201900482, loss (sparsity): 0.08330140262842178, loss (total): 0.014936443418264389\n",
      "epoches 0, steps 53, loss (recon_loss): 0.014760658144950867, loss (sparsity): 0.08403552323579788, loss (total): 0.01484469324350357\n",
      "epoches 0, steps 54, loss (recon_loss): 0.015874357894062996, loss (sparsity): 0.08419877290725708, loss (total): 0.015958556905388832\n",
      "epoches 0, steps 55, loss (recon_loss): 0.016261352226138115, loss (sparsity): 0.08482109010219574, loss (total): 0.016346173360943794\n",
      "epoches 0, steps 56, loss (recon_loss): 0.01438563410192728, loss (sparsity): 0.08375413715839386, loss (total): 0.01446938794106245\n",
      "epoches 0, steps 57, loss (recon_loss): 0.015992242842912674, loss (sparsity): 0.08271387219429016, loss (total): 0.016074957326054573\n",
      "epoches 0, steps 58, loss (recon_loss): 0.016254976391792297, loss (sparsity): 0.08231706917285919, loss (total): 0.01633729413151741\n",
      "epoches 0, steps 59, loss (recon_loss): 0.016788238659501076, loss (sparsity): 0.08396092057228088, loss (total): 0.01687219925224781\n",
      "epoches 0, steps 60, loss (recon_loss): 0.01453578844666481, loss (sparsity): 0.08306087553501129, loss (total): 0.014618849381804466\n",
      "epoches 0, steps 61, loss (recon_loss): 0.013645917177200317, loss (sparsity): 0.08604032546281815, loss (total): 0.013731957413256168\n",
      "epoches 0, steps 62, loss (recon_loss): 0.014517292380332947, loss (sparsity): 0.08379492908716202, loss (total): 0.0146010871976614\n",
      "epoches 0, steps 63, loss (recon_loss): 0.014320570044219494, loss (sparsity): 0.08296343684196472, loss (total): 0.014403533190488815\n",
      "epoches 0, steps 64, loss (recon_loss): 0.01410720031708479, loss (sparsity): 0.08118434250354767, loss (total): 0.014188384637236595\n",
      "epoches 0, steps 65, loss (recon_loss): 0.01357349008321762, loss (sparsity): 0.08164340257644653, loss (total): 0.013655133545398712\n",
      "epoches 0, steps 66, loss (recon_loss): 0.015029349364340305, loss (sparsity): 0.08349598199129105, loss (total): 0.015112845227122307\n",
      "epoches 0, steps 67, loss (recon_loss): 0.014076664112508297, loss (sparsity): 0.08494262397289276, loss (total): 0.014161606319248676\n",
      "epoches 0, steps 68, loss (recon_loss): 0.014651449397206306, loss (sparsity): 0.0836758092045784, loss (total): 0.014735125005245209\n",
      "epoches 0, steps 69, loss (recon_loss): 0.01432044617831707, loss (sparsity): 0.08138494193553925, loss (total): 0.014401830732822418\n",
      "epoches 0, steps 70, loss (recon_loss): 0.01273813284933567, loss (sparsity): 0.08256817609071732, loss (total): 0.012820701114833355\n",
      "epoches 0, steps 71, loss (recon_loss): 0.013592837378382683, loss (sparsity): 0.08406393229961395, loss (total): 0.0136769013479352\n",
      "epoches 0, steps 72, loss (recon_loss): 0.016012676060199738, loss (sparsity): 0.08689302206039429, loss (total): 0.01609956845641136\n",
      "epoches 0, steps 73, loss (recon_loss): 0.01658026874065399, loss (sparsity): 0.0879104733467102, loss (total): 0.016668180003762245\n",
      "epoches 0, steps 74, loss (recon_loss): 0.014799168333411217, loss (sparsity): 0.08376491814851761, loss (total): 0.014882933348417282\n",
      "epoches 0, steps 75, loss (recon_loss): 0.013666696846485138, loss (sparsity): 0.08113478124141693, loss (total): 0.01374783180654049\n",
      "epoches 0, steps 76, loss (recon_loss): 0.014671636745333672, loss (sparsity): 0.08222144842147827, loss (total): 0.014753858558833599\n",
      "epoches 0, steps 77, loss (recon_loss): 0.011526096612215042, loss (sparsity): 0.08296310901641846, loss (total): 0.011609059758484364\n",
      "epoches 0, steps 78, loss (recon_loss): 0.01244315318763256, loss (sparsity): 0.08468682318925858, loss (total): 0.012527840211987495\n",
      "epoches 0, steps 79, loss (recon_loss): 0.011710108257830143, loss (sparsity): 0.08471444249153137, loss (total): 0.011794822290539742\n",
      "epoches 0, steps 80, loss (recon_loss): 0.01326837856322527, loss (sparsity): 0.08435588330030441, loss (total): 0.013352734036743641\n",
      "epoches 0, steps 81, loss (recon_loss): 0.016060255467891693, loss (sparsity): 0.08451960980892181, loss (total): 0.016144774854183197\n",
      "epoches 0, steps 82, loss (recon_loss): 0.013709458522498608, loss (sparsity): 0.08358731120824814, loss (total): 0.013793045654892921\n",
      "epoches 0, steps 83, loss (recon_loss): 0.01553027518093586, loss (sparsity): 0.08753468096256256, loss (total): 0.015617810189723969\n",
      "epoches 0, steps 84, loss (recon_loss): 0.010977014899253845, loss (sparsity): 0.08264078199863434, loss (total): 0.01105965580791235\n",
      "epoches 0, steps 85, loss (recon_loss): 0.012836871668696404, loss (sparsity): 0.08380801975727081, loss (total): 0.012920679524540901\n",
      "epoches 0, steps 86, loss (recon_loss): 0.012857831083238125, loss (sparsity): 0.08417888730764389, loss (total): 0.01294200960546732\n",
      "epoches 0, steps 87, loss (recon_loss): 0.012805338948965073, loss (sparsity): 0.08548461645841599, loss (total): 0.012890823185443878\n",
      "epoches 0, steps 88, loss (recon_loss): 0.013050766661763191, loss (sparsity): 0.08503042906522751, loss (total): 0.013135797344148159\n",
      "epoches 0, steps 89, loss (recon_loss): 0.013731038197875023, loss (sparsity): 0.08448252081871033, loss (total): 0.013815520331263542\n",
      "epoches 0, steps 90, loss (recon_loss): 0.013021476566791534, loss (sparsity): 0.0837230384349823, loss (total): 0.013105199672281742\n",
      "epoches 0, steps 91, loss (recon_loss): 0.01289224810898304, loss (sparsity): 0.08379499614238739, loss (total): 0.012976042926311493\n",
      "epoches 0, steps 92, loss (recon_loss): 0.012171001173555851, loss (sparsity): 0.0846320167183876, loss (total): 0.012255633249878883\n",
      "epoches 0, steps 93, loss (recon_loss): 0.014408260583877563, loss (sparsity): 0.08699803054332733, loss (total): 0.01449525821954012\n",
      "epoches 0, steps 94, loss (recon_loss): 0.013609825633466244, loss (sparsity): 0.08416286110877991, loss (total): 0.01369398832321167\n",
      "epoches 0, steps 95, loss (recon_loss): 0.011728407815098763, loss (sparsity): 0.08290225267410278, loss (total): 0.011811310425400734\n",
      "epoches 0, steps 96, loss (recon_loss): 0.012176687829196453, loss (sparsity): 0.08385145664215088, loss (total): 0.012260539457201958\n",
      "epoches 0, steps 97, loss (recon_loss): 0.013614450581371784, loss (sparsity): 0.08635968714952469, loss (total): 0.013700810261070728\n",
      "epoches 0, steps 98, loss (recon_loss): 0.010846642777323723, loss (sparsity): 0.08343511819839478, loss (total): 0.010930078104138374\n",
      "epoches 0, steps 99, loss (recon_loss): 0.012549055740237236, loss (sparsity): 0.08465082943439484, loss (total): 0.01263370644301176\n",
      "epoches 0, steps 101, loss (recon_loss): 0.014310692436993122, loss (sparsity): 0.08647666871547699, loss (total): 0.014397169463336468\n",
      "epoches 0, steps 102, loss (recon_loss): 0.011293965391814709, loss (sparsity): 0.08382931351661682, loss (total): 0.011377794668078423\n",
      "epoches 0, steps 103, loss (recon_loss): 0.011305554769933224, loss (sparsity): 0.08461203426122665, loss (total): 0.011390166357159615\n",
      "epoches 0, steps 104, loss (recon_loss): 0.01344869565218687, loss (sparsity): 0.08638537675142288, loss (total): 0.013535081408917904\n",
      "epoches 0, steps 105, loss (recon_loss): 0.01434789877384901, loss (sparsity): 0.0862119048833847, loss (total): 0.01443411037325859\n",
      "epoches 0, steps 106, loss (recon_loss): 0.010421881452202797, loss (sparsity): 0.08363424241542816, loss (total): 0.010505516082048416\n",
      "epoches 0, steps 107, loss (recon_loss): 0.011544030159711838, loss (sparsity): 0.08309358358383179, loss (total): 0.011627123691141605\n",
      "epoches 0, steps 108, loss (recon_loss): 0.013224756345152855, loss (sparsity): 0.08597899973392487, loss (total): 0.013310735113918781\n",
      "epoches 0, steps 109, loss (recon_loss): 0.012773044407367706, loss (sparsity): 0.08574222028255463, loss (total): 0.01285878662019968\n",
      "epoches 0, steps 110, loss (recon_loss): 0.010416891425848007, loss (sparsity): 0.08520162105560303, loss (total): 0.010502093471586704\n",
      "epoches 0, steps 111, loss (recon_loss): 0.012087520211935043, loss (sparsity): 0.08465609699487686, loss (total): 0.012172176502645016\n",
      "epoches 0, steps 112, loss (recon_loss): 0.012017348781228065, loss (sparsity): 0.08328485488891602, loss (total): 0.01210063323378563\n",
      "epoches 0, steps 113, loss (recon_loss): 0.01199525035917759, loss (sparsity): 0.08490356802940369, loss (total): 0.01208015438169241\n",
      "epoches 0, steps 114, loss (recon_loss): 0.01173102855682373, loss (sparsity): 0.08566469699144363, loss (total): 0.011816693469882011\n",
      "epoches 0, steps 115, loss (recon_loss): 0.010583271272480488, loss (sparsity): 0.08456146717071533, loss (total): 0.01066783256828785\n",
      "epoches 0, steps 116, loss (recon_loss): 0.009612352587282658, loss (sparsity): 0.08395987749099731, loss (total): 0.009696312248706818\n",
      "epoches 0, steps 117, loss (recon_loss): 0.011959939263761044, loss (sparsity): 0.08538833260536194, loss (total): 0.012045327574014664\n",
      "epoches 0, steps 118, loss (recon_loss): 0.010938853025436401, loss (sparsity): 0.08319033682346344, loss (total): 0.011022043414413929\n",
      "epoches 0, steps 119, loss (recon_loss): 0.012517282739281654, loss (sparsity): 0.08713936060667038, loss (total): 0.012604421935975552\n",
      "epoches 0, steps 120, loss (recon_loss): 0.01141558401286602, loss (sparsity): 0.08475524932146072, loss (total): 0.011500339023768902\n",
      "epoches 0, steps 121, loss (recon_loss): 0.012445637956261635, loss (sparsity): 0.08386604487895966, loss (total): 0.012529503554105759\n",
      "epoches 0, steps 122, loss (recon_loss): 0.01091993972659111, loss (sparsity): 0.08392181992530823, loss (total): 0.011003861203789711\n",
      "epoches 0, steps 123, loss (recon_loss): 0.012089364230632782, loss (sparsity): 0.0856066346168518, loss (total): 0.012174970470368862\n",
      "epoches 0, steps 124, loss (recon_loss): 0.010914623737335205, loss (sparsity): 0.08637021481990814, loss (total): 0.01100099366158247\n"
     ]
    }
   ],
   "source": [
    "n_epoches = 1\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "\n",
    "for i_epoch in range(n_epoches):\n",
    "    for i_step, d in enumerate(train_loader):\n",
    "        d = d.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, embed = model(d)\n",
    "        recon_loss, sparsity_loss, total_loss = model.get_total_loss(d, recon, embed)\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i_step % 100:\n",
    "            print(f\"epoches {i_epoch}, steps {i_step}, loss (recon_loss): {recon_loss.item()}, loss (sparsity): {sparsity_loss.item()}, loss (total): {total_loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dbef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fd3468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
