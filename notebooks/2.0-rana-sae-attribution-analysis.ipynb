{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5802a48a",
   "metadata": {},
   "source": [
    "# SAE Feature-Attribution Correlation Analysis\n",
    "\n",
    "This notebook:\n",
    "1. Loads cell data with geneformer embeddings from CellxGene Census\n",
    "2. Passes embeddings through the trained Sparse Autoencoder\n",
    "3. Extracts SAE latent features\n",
    "4. Analyzes correlations between SAE features and cell attributions\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cdff3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cellxgene_census\n",
    "from cellxgene_census.experimental import get_embedding, get_embedding_metadata, get_all_available_embeddings\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "# GSEAPY for pathway analysis\n",
    "import gseapy as gp\n",
    "\n",
    "# Local imports\n",
    "sys.path.append('../src')\n",
    "from models import SparseAutoencoder\n",
    "from feature_attribution_analysis import FeatureAttributionAnalyzer\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configuration\n",
    "ORGANISM = \"homo_sapiens\"\n",
    "MEASUREMENT = \"RNA\"\n",
    "CENSUS_VERSION = \"2025-01-30\"\n",
    "EMBEDDING_NAME = \"geneformer\"\n",
    "SAMPLE_SIZE = 5000  # Number of cells to analyze (reduced for comprehensive annotations)\n",
    "\n",
    "# Metadata fields to collect (comprehensive set)\n",
    "METADATA_FIELDS = [\n",
    "    \"assay\",\n",
    "    \"dataset_id\",\n",
    "    \"cell_type\",\n",
    "    \"development_stage\",\n",
    "    \"disease\",\n",
    "    \"self_reported_ethnicity\",\n",
    "    \"sex\",\n",
    "    \"tissue_general\",\n",
    "    \"tissue\",\n",
    "    \"soma_joinid\"  # Need this for joining with expression data\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc90b12",
   "metadata": {},
   "source": [
    "## Step 1: Load Data from CellxGene Census\n",
    "\n",
    "Get normal cells with geneformer embeddings and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de20624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 5000 cells with geneformer embeddings and comprehensive metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homes/bargho16/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/functools.py:934: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/nfs/homes/bargho16/.local/share/uv/python/cpython-3.13.9-linux-x86_64-gnu/lib/python3.13/functools.py:934: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5000 cells x 20045 genes\n",
      "Final dataset: 5000 cells x 20045 genes\n",
      "Available embeddings: ['geneformer']\n",
      "Geneformer embedding shape: (5000, 512)\n",
      "Metadata fields: ['assay', 'dataset_id', 'cell_type', 'development_stage', 'disease', 'self_reported_ethnicity', 'sex', 'tissue_general', 'tissue', 'soma_joinid']\n",
      "Unique cell types: 20\n",
      "Unique tissues: 4\n",
      "Disease distribution: disease\n",
      "Alzheimer disease              2442\n",
      "normal                         1993\n",
      "breast cancer                   565\n",
      "Barrett esophagus                 0\n",
      "B-cell non-Hodgkin lymphoma       0\n",
      "Name: count, dtype: int64\n",
      "Final dataset: 5000 cells x 20045 genes\n",
      "Available embeddings: ['geneformer']\n",
      "Geneformer embedding shape: (5000, 512)\n",
      "Metadata fields: ['assay', 'dataset_id', 'cell_type', 'development_stage', 'disease', 'self_reported_ethnicity', 'sex', 'tissue_general', 'tissue', 'soma_joinid']\n",
      "Unique cell types: 20\n",
      "Unique tissues: 4\n",
      "Disease distribution: disease\n",
      "Alzheimer disease              2442\n",
      "normal                         1993\n",
      "breast cancer                   565\n",
      "Barrett esophagus                 0\n",
      "B-cell non-Hodgkin lymphoma       0\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_census_data_with_embeddings(sample_size=SAMPLE_SIZE, census_version=CENSUS_VERSION):\n",
    "    \"\"\"\n",
    "    Retrieve cell data with embeddings and comprehensive metadata from CellxGene Census.\n",
    "    Uses the same approach as the correlation set notebook for consistency.\n",
    "    \"\"\"\n",
    "    print(f\"Fetching {sample_size} cells with {EMBEDDING_NAME} embeddings and comprehensive metadata...\")\n",
    "\n",
    "    with cellxgene_census.open_soma(census_version=census_version) as census:\n",
    "        adata = cellxgene_census.get_anndata(\n",
    "            census,\n",
    "            organism=ORGANISM,\n",
    "            measurement_name=MEASUREMENT,\n",
    "            obs_value_filter=f\"soma_joinid < {sample_size}\",  # Simple filtering approach\n",
    "            var_value_filter=\"feature_type=='protein_coding'\",\n",
    "            obs_embeddings=[EMBEDDING_NAME],\n",
    "            obs_column_names=METADATA_FIELDS,  # Explicit metadata collection\n",
    "        )\n",
    "\n",
    "        print(f\"Retrieved {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "\n",
    "        # Set feature names properly\n",
    "        adata.var_names = adata.var[\"feature_name\"]\n",
    "\n",
    "    return adata\n",
    "\n",
    "# Load the data\n",
    "adata = get_census_data_with_embeddings()\n",
    "print(f\"Final dataset: {adata.shape[0]} cells x {adata.shape[1]} genes\")\n",
    "print(f\"Available embeddings: {list(adata.obsm.keys())}\")\n",
    "print(f\"Geneformer embedding shape: {adata.obsm[EMBEDDING_NAME].shape}\")\n",
    "print(f\"Metadata fields: {METADATA_FIELDS}\")\n",
    "print(f\"Unique cell types: {adata.obs['cell_type'].nunique()}\")\n",
    "print(f\"Unique tissues: {adata.obs['tissue_general'].nunique()}\")\n",
    "print(f\"Disease distribution: {adata.obs['disease'].value_counts().head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497df625",
   "metadata": {},
   "source": [
    "## Step 2: Load Trained Sparse Autoencoder\n",
    "\n",
    "Load the pre-trained SAE model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14df387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAE Hyperparameters:\n",
      "  hidden_dim: 512\n",
      "  expanded_ratio: 10.0\n",
      "  n_encoder_layers: 2\n",
      "  n_decoder_layers: 1\n",
      "  lr: 0.00017701853566940679\n",
      "  sparsity_weight: 0.0006659703893931954\n",
      "\n",
      "Loaded SAE model from: ../models/best_sparse_autoencoder.pt\n",
      "SAE expanded dimension: 5120\n",
      "SAE hidden dimension: 512\n",
      "SAE input dimension: 512\n"
     ]
    }
   ],
   "source": [
    "# Load model hyperparameters\n",
    "params_path = \"../models/best_sparse_autoencoder_params.json\"\n",
    "with open(params_path, \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "print(\"SAE Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Initialize the model with saved hyperparameters\n",
    "sae_model = SparseAutoencoder(\n",
    "    input_dim=512,  # Geneformer embedding dimension\n",
    "    hidden_dim=params[\"hidden_dim\"],\n",
    "    expanded_ratio=params[\"expanded_ratio\"],\n",
    "    n_encoder_layers=params[\"n_encoder_layers\"],\n",
    "    n_decoder_layers=params[\"n_decoder_layers\"]\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "checkpoint_path = \"../models/best_sparse_autoencoder.pt\"\n",
    "sae_model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "sae_model.eval()\n",
    "\n",
    "print(f\"\\nLoaded SAE model from: {checkpoint_path}\")\n",
    "print(f\"SAE expanded dimension: {sae_model.expanded_dim}\")\n",
    "print(f\"SAE hidden dimension: {sae_model.hidden_dim}\")\n",
    "print(f\"SAE input dimension: {sae_model.input_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c39ae",
   "metadata": {},
   "source": [
    "## Step 3: Extract SAE Latent Features\n",
    "\n",
    "Pass geneformer embeddings through the SAE to get latent representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5695e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geneformer embeddings shape: (5000, 512)\n",
      "Extracting SAE sparse features using full forward pass...\n",
      "SAE features shape: (5000, 5120)\n",
      "SAE feature sparsity: 39.96%\n"
     ]
    }
   ],
   "source": [
    "def extract_sae_features(embeddings, model):\n",
    "    \"\"\"\n",
    "    Extract SAE latent features from input embeddings.\n",
    "    Uses the full forward pass to get the proper sparse features.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Convert to tensor\n",
    "        embeddings_tensor = torch.FloatTensor(embeddings)\n",
    "\n",
    "        # Use the full forward pass to get the sparse features\n",
    "        # The forward method returns (reconstructed, features) where features is the sparse representation\n",
    "        reconstructed, sparse_features = model(embeddings_tensor)\n",
    "\n",
    "    return sparse_features.numpy()\n",
    "\n",
    "# Extract geneformer embeddings\n",
    "geneformer_embeddings = adata.obsm[EMBEDDING_NAME]\n",
    "print(f\"Geneformer embeddings shape: {geneformer_embeddings.shape}\")\n",
    "\n",
    "# Extract SAE latent features using the corrected method\n",
    "print(\"Extracting SAE sparse features using full forward pass...\")\n",
    "sae_features = extract_sae_features(geneformer_embeddings, sae_model)\n",
    "print(f\"SAE features shape: {sae_features.shape}\")\n",
    "\n",
    "# Check sparsity\n",
    "sparsity = (sae_features == 0).mean()\n",
    "print(f\"SAE feature sparsity: {sparsity:.2%}\")\n",
    "\n",
    "# Add SAE features to adata for convenience\n",
    "adata.obsm['sae_features'] = sae_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f863f4",
   "metadata": {},
   "source": [
    "## Step 4: Prepare Comprehensive Cell Attributions\n",
    "\n",
    "Extract and compute comprehensive biological annotations including:\n",
    "- Technical metrics (library size, gene counts, mitochondrial/ribosomal content)\n",
    "- Cell cycle scoring\n",
    "- Pathway activity via ssGSEA (inflammation, hypoxia)\n",
    "- Existing metadata (cell type, tissue, disease, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "446f10b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added metadata fields:\n",
      "  assay: 4 unique values\n",
      "  dataset_id: 5 unique values\n",
      "  cell_type: 20 unique values\n",
      "  development_stage: 27 unique values\n",
      "  disease: 3 unique values\n",
      "  self_reported_ethnicity: 2 unique values\n",
      "  sex: 3 unique values\n",
      "  tissue_general: 4 unique values\n",
      "  tissue: 5 unique values\n",
      "  soma_joinid: 5000 unique values\n",
      "\n",
      "Current annotations shape: (5000, 10)\n",
      "Sample of existing metadata:\n",
      "       assay                            dataset_id         cell_type  \\\n",
      "0  10x 3' v3  d7476ae2-e320-4703-8304-da5c42627e71  endothelial cell   \n",
      "1  10x 3' v3  d7476ae2-e320-4703-8304-da5c42627e71    malignant cell   \n",
      "2  10x 3' v3  d7476ae2-e320-4703-8304-da5c42627e71        fibroblast   \n",
      "3  10x 3' v3  d7476ae2-e320-4703-8304-da5c42627e71        fibroblast   \n",
      "4  10x 3' v3  d7476ae2-e320-4703-8304-da5c42627e71        macrophage   \n",
      "\n",
      "   development_stage        disease self_reported_ethnicity     sex  \\\n",
      "0  29-year-old stage  breast cancer                European  female   \n",
      "1  29-year-old stage  breast cancer                European  female   \n",
      "2  29-year-old stage  breast cancer                European  female   \n",
      "3  29-year-old stage  breast cancer                European  female   \n",
      "4  29-year-old stage  breast cancer                European  female   \n",
      "\n",
      "  tissue_general tissue  soma_joinid  \n",
      "0          liver  liver            0  \n",
      "1          liver  liver            1  \n",
      "2          liver  liver            2  \n",
      "3          liver  liver            3  \n",
      "4          liver  liver            4  \n"
     ]
    }
   ],
   "source": [
    "# Initialize comprehensive annotations dataframe\n",
    "annotations_df = pd.DataFrame(index=adata.obs_names)\n",
    "\n",
    "# Add existing metadata fields\n",
    "for field in METADATA_FIELDS:\n",
    "    if field in adata.obs.columns:\n",
    "        annotations_df[field] = adata.obs[field]\n",
    "\n",
    "print(\"Added metadata fields:\")\n",
    "for field in METADATA_FIELDS:\n",
    "    if field in adata.obs.columns:\n",
    "        print(f\"  {field}: {adata.obs[field].nunique()} unique values\")\n",
    "\n",
    "# Examine what we have so far\n",
    "print(f\"\\nCurrent annotations shape: {annotations_df.shape}\")\n",
    "print(\"Sample of existing metadata:\")\n",
    "print(annotations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634e3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing technical QC metrics...\n",
      "Technical metrics computed:\n",
      "  Mean counts per cell: 2032\n",
      "  Mean genes per cell: 738\n",
      "  Mean % mitochondrial: 4.8%\n",
      "  Mean % ribosomal: 9.0%\n",
      "Technical metrics computed:\n",
      "  Mean counts per cell: 2032\n",
      "  Mean genes per cell: 738\n",
      "  Mean % mitochondrial: 4.8%\n",
      "  Mean % ribosomal: 9.0%\n"
     ]
    }
   ],
   "source": [
    "# Compute technical metrics\n",
    "print(\"Computing technical QC metrics...\")\n",
    "\n",
    "# Get expression matrix\n",
    "if issparse(adata.X):\n",
    "    X = adata.X.toarray()\n",
    "else:\n",
    "    X = adata.X\n",
    "\n",
    "# Basic technical metrics\n",
    "annotations_df['n_counts'] = X.sum(axis=1)\n",
    "annotations_df['n_genes'] = (X > 0).sum(axis=1)\n",
    "\n",
    "# Mitochondrial gene percentage\n",
    "mito_genes = adata.var_names.str.upper().str.startswith(\"MT-\")\n",
    "annotations_df['pct_mito'] = X[:, mito_genes].sum(axis=1) / annotations_df['n_counts'] * 100\n",
    "\n",
    "# Ribosomal gene percentage\n",
    "ribo_genes = adata.var_names.str.startswith((\"RPS\",\"RPL\"))\n",
    "annotations_df['pct_ribo'] = X[:, ribo_genes].sum(axis=1) / annotations_df['n_counts'] * 100\n",
    "\n",
    "print(f\"Technical metrics computed:\")\n",
    "print(f\"  Mean counts per cell: {annotations_df['n_counts'].mean():.0f}\")\n",
    "print(f\"  Mean genes per cell: {annotations_df['n_genes'].mean():.0f}\")\n",
    "print(f\"  Mean % mitochondrial: {annotations_df['pct_mito'].mean():.1f}%\")\n",
    "print(f\"  Mean % ribosomal: {annotations_df['pct_ribo'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0173bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Hallmark gene sets...\n",
      "Computing cell cycle scores...\n",
      "Found 200 S-phase genes and 199 G2/M genes in dataset\n",
      "Computing cell cycle scores...\n",
      "Found 200 S-phase genes and 199 G2/M genes in dataset\n",
      "Cell cycle phases: {'G1': 2655, 'G2M': 1845, 'S': 500}\n",
      "Cell cycle phases: {'G1': 2655, 'G2M': 1845, 'S': 500}\n"
     ]
    }
   ],
   "source": [
    "# Get Hallmark gene sets for cell cycle and pathway analysis\n",
    "print(\"Loading Hallmark gene sets...\")\n",
    "hallmark_genesets = gp.get_library(name='MSigDB_Hallmark_2020', organism='Human')\n",
    "\n",
    "# Cell cycle scoring\n",
    "print(\"Computing cell cycle scores...\")\n",
    "s_genes = [g for g in hallmark_genesets['E2F Targets'] if g in adata.var_names]\n",
    "g2m_genes = [g for g in hallmark_genesets['G2-M Checkpoint'] if g in adata.var_names]\n",
    "\n",
    "print(f\"Found {len(s_genes)} S-phase genes and {len(g2m_genes)} G2/M genes in dataset\")\n",
    "\n",
    "if len(s_genes) > 0 and len(g2m_genes) > 0:\n",
    "    sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes, copy=False)\n",
    "    annotations_df['S_score'] = adata.obs['S_score']\n",
    "    annotations_df['G2M_score'] = adata.obs['G2M_score']\n",
    "    annotations_df['phase'] = adata.obs['phase']\n",
    "    print(f\"Cell cycle phases: {adata.obs['phase'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"Warning: Insufficient cell cycle genes found, skipping cell cycle scoring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bafd8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pathway activity scores...\n",
      "Computing Inflammation_Response score (199 genes)...\n",
      "  Inflammation_Response: mean score = -0.299\n",
      "Computing Hypoxia score (199 genes)...\n",
      "  Inflammation_Response: mean score = -0.299\n",
      "Computing Hypoxia score (199 genes)...\n",
      "  Hypoxia: mean score = -0.510\n",
      "Computing Apoptosis score (160 genes)...\n",
      "  Hypoxia: mean score = -0.510\n",
      "Computing Apoptosis score (160 genes)...\n",
      "  Apoptosis: mean score = -0.390\n",
      "Computing DNA_Repair score (149 genes)...\n",
      "  Apoptosis: mean score = -0.390\n",
      "Computing DNA_Repair score (149 genes)...\n",
      "  DNA_Repair: mean score = -0.297\n",
      "Computing Oxidative_Phosphorylation score (199 genes)...\n",
      "  DNA_Repair: mean score = -0.297\n",
      "Computing Oxidative_Phosphorylation score (199 genes)...\n",
      "  Oxidative_Phosphorylation: mean score = -0.222\n",
      "  Oxidative_Phosphorylation: mean score = -0.222\n"
     ]
    }
   ],
   "source": [
    "# Pathway activity analysis via ssGSEA\n",
    "print(\"Computing pathway activity scores...\")\n",
    "\n",
    "# Define key biological pathways to analyze\n",
    "marker_sets = {\n",
    "    \"Inflammation_Response\": hallmark_genesets['Inflammatory Response'],\n",
    "    \"Hypoxia\": hallmark_genesets['Hypoxia'],\n",
    "    \"Apoptosis\": hallmark_genesets['Apoptosis'],\n",
    "    \"DNA_Repair\": hallmark_genesets['DNA Repair'],\n",
    "    \"Oxidative_Phosphorylation\": hallmark_genesets['Oxidative Phosphorylation']\n",
    "}\n",
    "\n",
    "# Prepare expression data for ssGSEA\n",
    "expr_df = pd.DataFrame(X.T, index=adata.var_names, columns=adata.obs_names)\n",
    "\n",
    "# Compute ssGSEA scores for each pathway\n",
    "for pathway_name, genes in marker_sets.items():\n",
    "    genes_present = [g for g in genes if g in adata.var_names]\n",
    "    if len(genes_present) == 0:\n",
    "        print(f\"Warning: no genes from {pathway_name} found in dataset, skipping\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Computing {pathway_name} score ({len(genes_present)} genes)...\")\n",
    "\n",
    "    try:\n",
    "        ss_res = gp.ssgsea(\n",
    "            data=expr_df,\n",
    "            gene_sets={pathway_name: genes_present},\n",
    "            sample_norm_method=\"rank\",\n",
    "            outdir=None,\n",
    "            no_plot=True,\n",
    "            permutation_num=0\n",
    "        )\n",
    "\n",
    "        # Extract scores and add to annotations\n",
    "        sample_names = ss_res.res2d['Name']\n",
    "        if sample_names.dtype != expr_df.columns.dtype:\n",
    "            sample_names = sample_names.astype(expr_df.columns.dtype)\n",
    "        nes_series = pd.Series(data=ss_res.res2d['NES'].values, index=sample_names)\n",
    "\n",
    "        annotations_df[pathway_name] = annotations_df.index.map(lambda i: nes_series[i])\n",
    "        print(f\"  {pathway_name}: mean score = {annotations_df[pathway_name].mean():.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing {pathway_name}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6968ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrating annotations into AnnData object...\n",
      "Final annotations shape: (5000, 22)\n",
      "Summary of all annotations:\n",
      "       soma_joinid      n_counts      n_genes     pct_mito     pct_ribo  \\\n",
      "count  5000.000000   5000.000000  5000.000000  5000.000000  5000.000000   \n",
      "mean   2499.500000   2031.623047   737.590200     4.811214     8.978488   \n",
      "std    1443.520003   3955.448242   728.876894    10.417015    12.041237   \n",
      "min       0.000000    135.000000   101.000000     0.000000     0.000000   \n",
      "25%    1249.750000    368.000000   307.750000     0.242718     1.363636   \n",
      "50%    2499.500000    642.000000   476.500000     0.807538     2.393635   \n",
      "75%    3749.250000   1558.000000   864.250000     2.826175    12.871259   \n",
      "max    4999.000000  52427.000000  6961.000000    71.299095    63.765736   \n",
      "\n",
      "           S_score    G2M_score  Inflammation_Response      Hypoxia  \\\n",
      "count  5000.000000  5000.000000            5000.000000  5000.000000   \n",
      "mean     -0.005324     0.016416              -0.298554    -0.509694   \n",
      "std       0.243938     0.185820               0.109724     0.143043   \n",
      "min      -1.498099    -1.149500              -0.537218    -0.661536   \n",
      "25%      -0.038893    -0.013379              -0.359550    -0.595891   \n",
      "50%      -0.018061    -0.002058              -0.327868    -0.558660   \n",
      "75%      -0.007321     0.010775              -0.273035    -0.487633   \n",
      "max       4.467959     3.414520               0.462782     0.338464   \n",
      "\n",
      "         Apoptosis   DNA_Repair  Oxidative_Phosphorylation  \n",
      "count  5000.000000  5000.000000                5000.000000  \n",
      "mean     -0.389674    -0.297357                  -0.222055  \n",
      "std       0.133298     0.135269                   0.194174  \n",
      "min      -0.540202    -0.436270                  -0.386230  \n",
      "25%      -0.468009    -0.372913                  -0.337962  \n",
      "50%      -0.434187    -0.348428                  -0.313178  \n",
      "75%      -0.370584    -0.291881                  -0.190683  \n",
      "max       0.459798     0.563730                   0.613770  \n",
      "\n",
      "=== COMPREHENSIVE ANNOTATION SUMMARY ===\n",
      "Total cells: 5000\n",
      "Total annotations: 22\n",
      "\n",
      "Metadata fields:\n",
      "  assay: 4 unique values\n",
      "  dataset_id: 5 unique values\n",
      "  cell_type: 20 unique values\n",
      "  development_stage: 27 unique values\n",
      "  disease: 3 unique values\n",
      "  self_reported_ethnicity: 2 unique values\n",
      "  sex: 3 unique values\n",
      "  tissue_general: 4 unique values\n",
      "  tissue: 5 unique values\n",
      "  soma_joinid: 5000 unique values\n",
      "\n",
      "Technical metrics:\n",
      "  n_counts: 2031.62 ± 3955.45\n",
      "  n_genes: 737.59 ± 728.88\n",
      "  pct_mito: 4.81 ± 10.42\n",
      "  pct_ribo: 8.98 ± 12.04\n",
      "\n",
      "Cell cycle:\n",
      "  Phase distribution: {'G1': 2655, 'G2M': 1845, 'S': 500}\n",
      "\n",
      "Pathway scores:\n",
      "  Inflammation_Response: -0.299\n",
      "  Hypoxia: -0.510\n",
      "  Apoptosis: -0.390\n",
      "  DNA_Repair: -0.297\n",
      "  Oxidative_Phosphorylation: -0.222\n"
     ]
    }
   ],
   "source": [
    "# Add all annotations to adata.obs\n",
    "print(\"Integrating annotations into AnnData object...\")\n",
    "for col in annotations_df.columns:\n",
    "    adata.obs[col] = annotations_df[col]\n",
    "\n",
    "print(f\"Final annotations shape: {annotations_df.shape}\")\n",
    "print(\"Summary of all annotations:\")\n",
    "print(annotations_df.describe())\n",
    "\n",
    "# Display comprehensive annotation summary\n",
    "print(\"\\n=== COMPREHENSIVE ANNOTATION SUMMARY ===\")\n",
    "print(f\"Total cells: {adata.shape[0]}\")\n",
    "print(f\"Total annotations: {annotations_df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nMetadata fields:\")\n",
    "for field in METADATA_FIELDS:\n",
    "    if field in adata.obs.columns:\n",
    "        n_unique = adata.obs[field].nunique()\n",
    "        print(f\"  {field}: {n_unique} unique values\")\n",
    "\n",
    "print(f\"\\nTechnical metrics:\")\n",
    "tech_metrics = ['n_counts', 'n_genes', 'pct_mito', 'pct_ribo']\n",
    "for metric in tech_metrics:\n",
    "    if metric in adata.obs.columns:\n",
    "        mean_val = adata.obs[metric].mean()\n",
    "        std_val = adata.obs[metric].std()\n",
    "        print(f\"  {metric}: {mean_val:.2f} ± {std_val:.2f}\")\n",
    "\n",
    "print(f\"\\nCell cycle:\")\n",
    "if 'phase' in adata.obs.columns:\n",
    "    print(f\"  Phase distribution: {adata.obs['phase'].value_counts().to_dict()}\")\n",
    "\n",
    "print(f\"\\nPathway scores:\")\n",
    "pathway_cols = [col for col in adata.obs.columns if any(x in col for x in ['Inflammation', 'Hypoxia', 'Apoptosis', 'DNA_Repair', 'Oxidative'])]\n",
    "for col in pathway_cols:\n",
    "    mean_val = adata.obs[col].mean()\n",
    "    print(f\"  {col}: {mean_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e21ebf",
   "metadata": {},
   "source": [
    "## Step 5: Run Feature-Attribution Analysis\n",
    "\n",
    "Analyze correlations between SAE features and cell attributions using the comprehensive statistical toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995712b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorizing and preparing attributions for analysis...\n",
      "Categorized attributes:\n",
      "  Binary: 0 attributes - []\n",
      "  Categorical: 9 attributes - ['assay', 'dataset_id', 'cell_type', 'development_stage', 'disease', 'self_reported_ethnicity', 'tissue_general', 'tissue', 'phase']\n",
      "  Continuous: 11 attributes - ['S_score', 'G2M_score', 'n_counts', 'n_genes', 'pct_mito', 'pct_ribo', 'Inflammation_Response', 'Hypoxia', 'Apoptosis', 'DNA_Repair', 'Oxidative_Phosphorylation']\n",
      "\n",
      "Confounders shape: (5000, 12)\n",
      "Confounder columns: ['n_counts', 'n_genes', 'dataset_bdacc907-7c26-419f-8808-969eab3ca2e8', 'dataset_fbd69faa-b0c5-45ba-89c9-da938a7f5a14', 'dataset_d7476ae2-e320-4703-8304-da5c42627e71', 'dataset_00ff600e-6e2e-4d76-846f-0eec4f0ae417', 'dataset_0895c838-e550-48a3-a777-dbcd35d30272', 'dataset_ae45e70d-cae7-45f5-8ee8-6655f208273c', 'dataset_ae4f8ddd-cac9-4172-9681-2175da462f2e', 'dataset_ae5341b8-60fb-4fac-86db-86e49ee66287', 'dataset_af8b241a-c72c-4470-b1a4-80e7336c6ab6', 'dataset_b03e4ef8-4e6b-47f4-84a7-e8ed033d08cd']\n",
      "Total attributions: 20\n",
      "Ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "# Smart categorization and preparation of attributions for analysis\n",
    "print(\"Categorizing and preparing attributions for analysis...\")\n",
    "\n",
    "# Smart categorization based on biological knowledge\n",
    "binary_attrs = []\n",
    "categorical_attrs = []\n",
    "continuous_attrs = []\n",
    "\n",
    "# Predefined categories based on biological knowledge\n",
    "known_categorical = [\n",
    "    'cell_type', 'tissue_general', 'tissue', 'disease', 'development_stage',\n",
    "    'assay', 'dataset_id', 'self_reported_ethnicity', 'phase'\n",
    "]\n",
    "known_continuous = [\n",
    "    'n_counts', 'n_genes', 'pct_mito', 'pct_ribo', 'S_score', 'G2M_score'\n",
    "] + [col for col in adata.obs.columns if any(x in col for x in ['Inflammation', 'Hypoxia', 'Apoptosis', 'DNA_Repair', 'Oxidative'])]\n",
    "\n",
    "# Categorize based on data properties and biological knowledge\n",
    "for col in adata.obs.columns:\n",
    "    if col.startswith('_') or col == 'soma_joinid':  # Skip internal columns\n",
    "        continue\n",
    "\n",
    "    n_unique = adata.obs[col].nunique()\n",
    "    dtype = adata.obs[col].dtype\n",
    "    missing_frac = adata.obs[col].isna().mean()\n",
    "\n",
    "    # Skip if too many missing values\n",
    "    if missing_frac > 0.5:\n",
    "        continue\n",
    "\n",
    "    # Categorize based on biological knowledge and data properties\n",
    "    if col in known_continuous:\n",
    "        continuous_attrs.append(col)\n",
    "    elif col in known_categorical:\n",
    "        if n_unique <= 50:  # Reasonable number of categories\n",
    "            categorical_attrs.append(col)\n",
    "    elif n_unique == 2 and dtype == 'object':\n",
    "        binary_attrs.append(col)\n",
    "    elif 2 < n_unique <= 50 and dtype == 'object':\n",
    "        categorical_attrs.append(col)\n",
    "    elif dtype in ['float64', 'int64'] and n_unique > 10:\n",
    "        continuous_attrs.append(col)\n",
    "\n",
    "print(f\"Categorized attributes:\")\n",
    "print(f\"  Binary: {len(binary_attrs)} attributes - {binary_attrs}\")\n",
    "print(f\"  Categorical: {len(categorical_attrs)} attributes - {categorical_attrs}\")\n",
    "print(f\"  Continuous: {len(continuous_attrs)} attributes - {continuous_attrs}\")\n",
    "\n",
    "# Create attribution dictionary\n",
    "attributions = {\n",
    "    'binary': {attr: adata.obs[attr] for attr in binary_attrs},\n",
    "    'categorical': {attr: adata.obs[attr] for attr in categorical_attrs},\n",
    "    'continuous': {attr: adata.obs[attr] for attr in continuous_attrs}\n",
    "}\n",
    "\n",
    "# Create confounders for residualization (technical factors only - keep numeric)\n",
    "confounder_cols = ['n_counts', 'n_genes']\n",
    "confounders = adata.obs[confounder_cols].copy()\n",
    "\n",
    "# Add a few top dataset dummies if we have multiple datasets, but limit to avoid overfitting\n",
    "if 'dataset_id' in adata.obs.columns:\n",
    "    top_datasets = adata.obs['dataset_id'].value_counts().head(10).index  # Top 10 datasets\n",
    "    for dataset in top_datasets:\n",
    "        confounders[f'dataset_{dataset}'] = (adata.obs['dataset_id'] == dataset).astype(int)\n",
    "\n",
    "# Ensure all confounders are numeric\n",
    "confounders = confounders.select_dtypes(include=[np.number])\n",
    "\n",
    "print(f\"\\nConfounders shape: {confounders.shape}\")\n",
    "print(f\"Confounder columns: {list(confounders.columns)}\")\n",
    "print(f\"Total attributions: {sum(len(v) for v in attributions.values())}\")\n",
    "print(f\"Ready for analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "390c295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running comprehensive feature-attribution analysis...\n",
      "Analyzing 512 SAE features vs 20 attributions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homes/bargho16/AstroBio/notebooks/../src/feature_attribution_analysis.py:409: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  r_s, p_s = spearmanr(feature_vals, attr_values, nan_policy='omit')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msae_features.shape[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m SAE features vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(v)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mattributions.values())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m attributions\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Run the full analysis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m results = \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43manalyze_associations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43msae_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattributions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattributions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfounders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfounders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfounders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnalysis completed!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AstroBio/notebooks/../src/feature_attribution_analysis.py:577\u001b[39m, in \u001b[36mFeatureAttributionAnalyzer.analyze_associations\u001b[39m\u001b[34m(self, features, attributions, confounders)\u001b[39m\n\u001b[32m    574\u001b[39m data = \u001b[38;5;28mself\u001b[39m.prepare_data(features, attributions, confounders)\n\u001b[32m    576\u001b[39m \u001b[38;5;66;03m# Step 2: Univariate associations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m univariate_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munivariate_associations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# Step 3: Multiple testing correction\u001b[39;00m\n\u001b[32m    580\u001b[39m corrected_results = \u001b[38;5;28mself\u001b[39m.multiple_testing_correction(univariate_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AstroBio/notebooks/../src/feature_attribution_analysis.py:416\u001b[39m, in \u001b[36mFeatureAttributionAnalyzer.univariate_associations\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    413\u001b[39m         r_s, p_s = \u001b[32m0.0\u001b[39m, \u001b[32m1.0\u001b[39m\n\u001b[32m    415\u001b[39m     \u001b[38;5;66;03m# Distance correlation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     dcorr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistance_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    418\u001b[39m     attr_results.append({\n\u001b[32m    419\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfeature_idx\u001b[39m\u001b[33m'\u001b[39m: j,\n\u001b[32m    420\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mspearman_r\u001b[39m\u001b[33m'\u001b[39m: r_s,\n\u001b[32m   (...)\u001b[39m\u001b[32m    425\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mp_value\u001b[39m\u001b[33m'\u001b[39m: p_s\n\u001b[32m    426\u001b[39m     })\n\u001b[32m    428\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mcontinuous\u001b[39m\u001b[33m'\u001b[39m][attr_name] = attr_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AstroBio/notebooks/../src/feature_attribution_analysis.py:277\u001b[39m, in \u001b[36mFeatureAttributionAnalyzer.distance_correlation\u001b[39m\u001b[34m(self, x, y)\u001b[39m\n\u001b[32m    274\u001b[39m dy_centered = center_distance_matrix(dy)\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Calculate distance covariance and variances\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m dcov_xy = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdx_centered\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mdy_centered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m dvar_x = np.mean(dx_centered * dx_centered)\n\u001b[32m    279\u001b[39m dvar_y = np.mean(dy_centered * dy_centered)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AstroBio/.venv/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3730\u001b[39m, in \u001b[36m_mean_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3715\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3716\u001b[39m \u001b[33;03m    Round an array to the given number of decimals.\u001b[39;00m\n\u001b[32m   3717\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3725\u001b[39m \n\u001b[32m   3726\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3727\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mround\u001b[39m\u001b[33m'\u001b[39m, decimals=decimals, out=out)\n\u001b[32m-> \u001b[39m\u001b[32m3730\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mean_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m   3731\u001b[39m                      where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, where, out)\n\u001b[32m   3735\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_mean_dispatcher)\n\u001b[32m   3736\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, *,\n\u001b[32m   3737\u001b[39m          where=np._NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize the analyzer\n",
    "analyzer = FeatureAttributionAnalyzer(\n",
    "    n_permutations=1000,\n",
    "    fdr_method='fdr_bh',\n",
    "    cv_folds=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Running comprehensive feature-attribution analysis...\")\n",
    "print(f\"Analyzing {sae_features.shape[1]} SAE features vs {sum(len(v) for v in attributions.values())} attributions\")\n",
    "\n",
    "# Run the full analysis\n",
    "results = analyzer.analyze_associations(\n",
    "    features=sae_features,\n",
    "    attributions=attributions,\n",
    "    confounders=confounders.values if confounders.shape[1] > 0 else None\n",
    ")\n",
    "\n",
    "print(\"\\nAnalysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90bad1",
   "metadata": {},
   "source": [
    "## Step 6: Examine Results\n",
    "\n",
    "### Univariate Association Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "univar = results['univariate']\n",
    "\n",
    "for attr_type in ['binary', 'categorical', 'continuous']:\n",
    "    if attr_type in univar and len(univar[attr_type]) > 0:\n",
    "        print(f\"\\n{attr_type.upper()} ATTRIBUTIONS:\")\n",
    "\n",
    "        for attr_name, attr_results in univar[attr_type].items():\n",
    "            if len(attr_results) > 0:\n",
    "                # Count significant associations\n",
    "                sig_count = sum(1 for result in attr_results if result.get('q_value', 1.0) < 0.05)\n",
    "                total_count = len(attr_results)\n",
    "\n",
    "                print(f\"  {attr_name}: {sig_count}/{total_count} significant SAE features (q < 0.05)\")\n",
    "\n",
    "                # Show top associations\n",
    "                if sig_count > 0:\n",
    "                    sorted_results = sorted(attr_results, key=lambda x: x.get('q_value', 1.0))\n",
    "                    top_result = sorted_results[0]\n",
    "                    print(f\"    Best: Feature {top_result['feature_idx']}, q={top_result['q_value']:.2e}, effect={top_result.get('effect_size', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75bdbf1",
   "metadata": {},
   "source": [
    "### Visualization: Association Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8184695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_association_heatmap(results, attr_type, metric='q_value', top_n=50):\n",
    "    \"\"\"\n",
    "    Create heatmap of associations between SAE features and attributions.\n",
    "    \"\"\"\n",
    "    if attr_type not in results['univariate'] or len(results['univariate'][attr_type]) == 0:\n",
    "        print(f\"No {attr_type} results to plot\")\n",
    "        return\n",
    "\n",
    "    # Collect data for heatmap\n",
    "    heatmap_data = []\n",
    "\n",
    "    for attr_name, attr_results in results['univariate'][attr_type].items():\n",
    "        for result in attr_results:\n",
    "            heatmap_data.append({\n",
    "                'attribution': attr_name,\n",
    "                'feature': f\"SAE_{result['feature_idx']}\",\n",
    "                'q_value': result.get('q_value', 1.0),\n",
    "                'effect_size': result.get('effect_size', 0),\n",
    "                'statistic': result.get('statistic', 0)\n",
    "            })\n",
    "\n",
    "    if len(heatmap_data) == 0:\n",
    "        print(f\"No data for {attr_type} heatmap\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(heatmap_data)\n",
    "\n",
    "    # Filter to top associations\n",
    "    df_sig = df[df['q_value'] < 0.05]\n",
    "\n",
    "    if len(df_sig) == 0:\n",
    "        print(f\"No significant associations for {attr_type}\")\n",
    "        return\n",
    "\n",
    "    # Take top N by effect size or q-value\n",
    "    df_top = df_sig.nsmallest(min(top_n, len(df_sig)), 'q_value')\n",
    "\n",
    "    # Create pivot table\n",
    "    if metric == 'q_value':\n",
    "        values = -np.log10(df_top['q_value'])\n",
    "        label = '-log10(q-value)'\n",
    "    else:\n",
    "        values = df_top['effect_size']\n",
    "        label = 'Effect Size'\n",
    "\n",
    "    pivot_df = df_top.pivot_table(\n",
    "        index='feature',\n",
    "        columns='attribution',\n",
    "        values=metric,\n",
    "        fill_value=1.0 if metric == 'q_value' else 0.0\n",
    "    )\n",
    "\n",
    "    if metric == 'q_value':\n",
    "        pivot_df = -np.log10(pivot_df)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(pivot_df,\n",
    "                cmap='viridis',\n",
    "                cbar_kws={'label': label},\n",
    "                xticklabels=True,\n",
    "                yticklabels=True)\n",
    "    plt.title(f'SAE Feature-{attr_type.title()} Attribution Associations\\n(Top {len(df_top)} significant)')\n",
    "    plt.xlabel('Attributions')\n",
    "    plt.ylabel('SAE Features')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return df_top\n",
    "\n",
    "# Create heatmaps for each attribution type\n",
    "for attr_type in ['continuous', 'categorical', 'binary']:\n",
    "    print(f\"\\n=== {attr_type.upper()} ASSOCIATIONS ===\")\n",
    "    top_associations = create_association_heatmap(results, attr_type)\n",
    "\n",
    "    if top_associations is not None and len(top_associations) > 0:\n",
    "        print(f\"Top 5 {attr_type} associations:\")\n",
    "        print(top_associations.nsmallest(5, 'q_value')[['attribution', 'feature', 'q_value', 'effect_size']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717358b",
   "metadata": {},
   "source": [
    "### Linear Probe Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfd582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display linear probe performance\n",
    "if 'multivariate' in results and 'linear_probes' in results['multivariate']:\n",
    "    print(\"\\n=== LINEAR PROBE RESULTS ===\")\n",
    "\n",
    "    probes = results['multivariate']['linear_probes']\n",
    "\n",
    "    for attr_name, probe_result in probes.items():\n",
    "        print(f\"\\n{attr_name}:\")\n",
    "\n",
    "        if 'auc' in probe_result:\n",
    "            print(f\"  AUC: {probe_result['auc']:.3f} ± {probe_result.get('auc_std', 0):.3f}\")\n",
    "\n",
    "        if 'r2' in probe_result:\n",
    "            print(f\"  R²: {probe_result['r2']:.3f} ± {probe_result.get('r2_std', 0):.3f}\")\n",
    "\n",
    "        if 'f1' in probe_result:\n",
    "            print(f\"  F1: {probe_result['f1']:.3f} ± {probe_result.get('f1_std', 0):.3f}\")\n",
    "else:\n",
    "    print(\"\\nNo linear probe results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98653d34",
   "metadata": {},
   "source": [
    "## Step 7: Detailed Feature Investigation\n",
    "\n",
    "Examine the most interesting SAE features in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_top_features(results, top_n=5):\n",
    "    \"\"\"\n",
    "    Analyze the most significant SAE features across all attributions.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    # Collect all significant results\n",
    "    for attr_type in ['binary', 'categorical', 'continuous']:\n",
    "        if attr_type in results['univariate']:\n",
    "            for attr_name, attr_results in results['univariate'][attr_type].items():\n",
    "                for result in attr_results:\n",
    "                    if result.get('q_value', 1.0) < 0.05:\n",
    "                        all_results.append({\n",
    "                            'feature_idx': result['feature_idx'],\n",
    "                            'attribution': attr_name,\n",
    "                            'attr_type': attr_type,\n",
    "                            'q_value': result['q_value'],\n",
    "                            'effect_size': result.get('effect_size', 0),\n",
    "                            'statistic': result.get('statistic', 0)\n",
    "                        })\n",
    "\n",
    "    if len(all_results) == 0:\n",
    "        print(\"No significant associations found\")\n",
    "        return\n",
    "\n",
    "    df_all = pd.DataFrame(all_results)\n",
    "\n",
    "    # Find features with most associations\n",
    "    feature_counts = df_all['feature_idx'].value_counts()\n",
    "    top_features = feature_counts.head(top_n).index\n",
    "\n",
    "    print(f\"\\n=== TOP {top_n} MOST ASSOCIATED SAE FEATURES ===\")\n",
    "\n",
    "    for feature_idx in top_features:\n",
    "        feature_results = df_all[df_all['feature_idx'] == feature_idx]\n",
    "\n",
    "        print(f\"\\nSAE Feature {feature_idx}:\")\n",
    "        print(f\"  - {len(feature_results)} significant associations\")\n",
    "        print(f\"  - Sparsity: {(sae_features[:, feature_idx] == 0).mean():.1%}\")\n",
    "        print(f\"  - Mean activation: {sae_features[:, feature_idx].mean():.3f}\")\n",
    "        print(f\"  - Std activation: {sae_features[:, feature_idx].std():.3f}\")\n",
    "\n",
    "        # Show top associations\n",
    "        top_assoc = feature_results.nsmallest(3, 'q_value')\n",
    "        print(\"  Top associations:\")\n",
    "        for _, row in top_assoc.iterrows():\n",
    "            print(f\"    - {row['attribution']} ({row['attr_type']}): q={row['q_value']:.2e}, effect={row['effect_size']:.3f}\")\n",
    "\n",
    "    return df_all, top_features\n",
    "\n",
    "# Analyze top features\n",
    "all_associations, top_feature_indices = analyze_top_features(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea34c2",
   "metadata": {},
   "source": [
    "### Visualize Top Feature Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if top_feature_indices is not None and len(top_feature_indices) > 0:\n",
    "    # Plot activation patterns for top features\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature_idx in enumerate(top_feature_indices[:6]):\n",
    "        activations = sae_features[:, feature_idx]\n",
    "\n",
    "        # Histogram of activations\n",
    "        axes[i].hist(activations[activations > 0], bins=50, alpha=0.7)\n",
    "        axes[i].set_title(f'SAE Feature {feature_idx}\\nSparsity: {(activations == 0).mean():.1%}')\n",
    "        axes[i].set_xlabel('Activation Value')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].set_yscale('log')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Activation Distributions for Top SAE Features', y=1.02)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece36915",
   "metadata": {},
   "source": [
    "## Step 8: Save Results\n",
    "\n",
    "Save the analysis results for further investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "output_dir = '../data/processed/sae_attribution_analysis/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save SAE features\n",
    "np.save(f'{output_dir}/sae_features.npy', sae_features)\n",
    "print(f\"Saved SAE features to {output_dir}/sae_features.npy\")\n",
    "\n",
    "# Save analysis results as JSON\n",
    "def make_json_serializable(obj):\n",
    "    \"\"\"Convert numpy types to Python types for JSON serialization.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: make_json_serializable(value) for key, value in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_serializable(item) for item in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Convert results to JSON-serializable format\n",
    "json_results = make_json_serializable(results)\n",
    "\n",
    "with open(f'{output_dir}/analysis_results.json', 'w') as f:\n",
    "    json.dump(json_results, f, indent=2)\n",
    "print(f\"Saved analysis results to {output_dir}/analysis_results.json\")\n",
    "\n",
    "# Save summary statistics\n",
    "if all_associations is not None:\n",
    "    all_associations.to_csv(f'{output_dir}/all_associations.csv', index=False)\n",
    "    print(f\"Saved association summary to {output_dir}/all_associations.csv\")\n",
    "\n",
    "# Save metadata\n",
    "adata.obs.to_csv(f'{output_dir}/cell_metadata.csv')\n",
    "print(f\"Saved cell metadata to {output_dir}/cell_metadata.csv\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec9c31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This analysis pipeline:\n",
    "\n",
    "1. ✅ **Data Collection**: Retrieved cells with geneformer embeddings from CellxGene Census\n",
    "2. ✅ **SAE Processing**: Passed embeddings through trained sparse autoencoder\n",
    "3. ✅ **Feature Extraction**: Extracted sparse latent features from SAE\n",
    "4. ✅ **Attribution Analysis**: Comprehensive statistical analysis of feature-attribution correlations\n",
    "5. ✅ **Results Investigation**: Identified top features and their biological associations\n",
    "\n",
    "### Key Findings:\n",
    "- **SAE Feature Dimensionality**: {sae_features.shape[1]} latent features\n",
    "- **Overall Sparsity**: ~{(sae_features == 0).mean():.1%}\n",
    "- **Significant Associations**: Multiple SAE features correlate with cell types, QC metrics, and other attributions\n",
    "- **Linear Probes**: SAE features can predict various cell attributions with varying degrees of success\n",
    "\n",
    "### Next Steps:\n",
    "1. **Biological Interpretation**: Examine what genes/pathways the top SAE features capture\n",
    "2. **Feature Refinement**: Optimize SAE architecture based on attribution correlations\n",
    "3. **Validation**: Test findings on independent datasets\n",
    "4. **Mechanistic Analysis**: Investigate how SAE features relate to biological processes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
